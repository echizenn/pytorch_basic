{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9acb23a6",
   "metadata": {},
   "source": [
    "# 1\n",
    "## (a)  \n",
    "モデルが変わったので、model関数を変更する必要がある。  \n",
    "5.5節のコードの書き方であれば、それ以上に変更点はない。一方、勾配を自分で計算していて5.4節のコードなら、grad_fnの中身(dmodel_dwとdmodel_db)も新しいモデルに対応したものに変える必要がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f312baf",
   "metadata": {},
   "source": [
    "## (b)\n",
    "損失の計算方法や、5.5節でのbackwardの部分はコード上ではモデルが変更されたことを知り得ないようになっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2073b6c4",
   "metadata": {},
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "530316a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475927f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w2, w1, b):\n",
    "    \"\"\"\n",
    "    モデルだけ変わる\n",
    "    \"\"\"\n",
    "    return w2*t_u**2 + w1*t_u + b\n",
    "\n",
    "def loss_fn(t_p, t_c):\n",
    "    \"\"\"\n",
    "    本の内容と同じ\n",
    "    \"\"\"\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()\n",
    "\n",
    "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u, train_t_c, val_t_c):\n",
    "    \"\"\"\n",
    "    本の内容と同じ\n",
    "    \"\"\"\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_t_p = model(train_t_u, *params)\n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "        \n",
    "        val_t_p = model(val_t_u, *params)\n",
    "        val_loss = loss_fn(val_t_p, val_t_c)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch <= 3 or epoch % 500 == 0:\n",
    "            print(f\"Epoch {epoch}, Training Loss {train_loss.item():.4f}, Validation loss {val_loss.item():.4f}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7d51604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss 13651680.0000, Validation loss 2969537.5000\n",
      "Epoch 2, Training Loss 11047436.0000, Validation loss 2403958.5000\n",
      "Epoch 3, Training Loss 8727637.0000, Validation loss 1900049.2500\n",
      "Epoch 500, Training Loss 3.2139, Validation loss 15.5588\n",
      "Epoch 1000, Training Loss 2.8043, Validation loss 12.6439\n",
      "Epoch 1500, Training Loss 2.6471, Validation loss 10.6635\n",
      "Epoch 2000, Training Loss 2.6139, Validation loss 9.7028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0054, -0.0674, -1.2254], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adam version\n",
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)\n",
    "\n",
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "train_t_u = t_u[train_indices]\n",
    "train_t_c = t_c[train_indices]\n",
    "\n",
    "val_t_u = t_u[val_indices]\n",
    "val_t_c = t_c[val_indices]\n",
    "\n",
    "# train_t_un = 0.1 * train_t_u\n",
    "# val_t_un = 0.1 * val_t_u\n",
    "\n",
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True) # 変数の数が一つ増えた\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.Adam([params], lr=learning_rate)\n",
    "training_loop(n_epochs = 2000, optimizer = optimizer, params = params, train_t_u = train_t_u, val_t_u = val_t_u,\n",
    "              train_t_c = train_t_c, val_t_c = val_t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c854de",
   "metadata": {},
   "source": [
    "訓練データの損失は下がったが、テストデータの損失は高くなった。  \n",
    "過学習していることが想像される。  \n",
    "\n",
    "## (d)  \n",
    "テストデータの損失がかなり悪いことから、結果は悪化したと言える。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
